# Auditability Protocol

**This protocol is MANDATORY for ALL agents in the Value Consulting system — current and future. Every agent, every engagement, every output must be auditable.**

## Governing Principle

> Every agent is auditable. Every engagement is auditable. Every output is auditable. No exceptions.

A consultant, auditor, or future agent must be able to reconstruct what happened during any engagement by reading the engagement directory alone — without needing the original conversation context.

## What "Auditable" Means

### 1. Agent Execution is Auditable

Every agent MUST leave a trace of its work:

| Requirement | Where | Format |
|-------------|-------|--------|
| **Journal Entry** | `ENGAGEMENT_JOURNAL.md` | Append-only log with agent name, date, inputs, outputs, decisions, and consultant feedback |
| **Telemetry Block** | Inside journal entry | `<!-- TELEMETRY_START -->` block with timestamps, file counts, error tracking, quality self-check |
| **Checkpoint Decisions** | Inside journal entry | Record of what was presented at each checkpoint and how the consultant responded |
| **Session ID** | `.engagement_session_id` | Links all agent executions within a single engagement run |

### 2. Outputs are Auditable

Every deliverable (HTML dashboard, Excel model, use case document, workshop deck) MUST include:

| Requirement | Implementation |
|-------------|---------------|
| **Generation metadata** | Footer or metadata section: agent name, generation date, engagement ID |
| **Data provenance** | Every number, chart, or claim traces to a source: evidence ID, benchmark reference, client data, or assumption |
| **Assumption register** | All assumptions explicitly listed with confidence levels (High/Medium/Low) and validation owners |
| **Version tracking** | If an output is regenerated, the new version notes what changed and why |

### 3. Engagements are Auditable

The engagement directory structure MUST support full reconstruction:

```
engagements/[client]/[YYYY-MM_domain_type]/
├── ENGAGEMENT_CONTEXT.md      ← Cumulative state (each agent reads + updates)
├── ENGAGEMENT_JOURNAL.md      ← Append-only execution log
├── .engagement_session_id     ← Session identifier
├── inputs/                    ← Raw inputs (transcripts, documents)
├── outputs/                   ← All generated deliverables
└── CLIENT_PROFILE.md          ← (parent directory) Cross-engagement context
```

### 4. Decisions are Auditable

Every consultant checkpoint MUST be logged:

```markdown
### Checkpoint: [Agent Name] — [Checkpoint Type]
**Date:** [ISO timestamp]
**Presented:** [Summary of what was shown to consultant]
**Decision:** [Approved / Approved with changes / Rejected]
**Changes Requested:** [If any]
**Rationale:** [Why this decision was made]
```

## Rules for New Agents

Any agent added to the system in the future MUST include:

1. **Journal Entry (MANDATORY)** section — append to `ENGAGEMENT_JOURNAL.md` on completion
2. **Telemetry Protocol (MANDATORY)** section — structured `<!-- TELEMETRY_START -->` block
3. **At least 2 Consultant Checkpoints** — one before generation, one after generation
4. **Evidence tracing** — every claim in outputs must reference its source
5. **Assumption documentation** — every assumption must be explicit with confidence level

## Rules for Outputs

Any output generated by any agent MUST:

1. **Be self-contained** — readable without the generating conversation
2. **Include provenance** — which agent generated it, when, from what inputs
3. **Trace data to sources** — no unexplained numbers or unsourced claims
4. **Document assumptions** — with confidence levels and sensitivity flags
5. **Be reproducible** — given the same inputs, another run should produce equivalent output

## Audit Trail Example

A properly auditable engagement journal entry looks like:

```markdown
### Market Context Researcher — 2026-02-15
**Status:** Complete (Consultant Approved)
**Inputs:** Annual Report 2024 (PDF, 42 pages), NCUA Call Report (web)
**Outputs:** market_context_validated.md (28KB), competitor_matrix.md (12KB)
**Key Findings:** C/I ratio 68.2% vs industry 62.1%; digital adoption 34% vs peer avg 51%
**Assumptions:** Used NCUA 2024 Q4 data (latest available); peer group = top 5 CUs by assets
**Checkpoint #1:** Approved — consultant confirmed peer group selection
**Checkpoint #2:** Approved with changes — consultant added USAA as additional competitor
**Data Gaps:** Investment services revenue not broken out in annual report (flagged for client)

<!-- TELEMETRY_START -->
- Agent: market-context-researcher
- Session ID: nfis-2026-02
- Start Time: 2026-02-15T09:00:00Z
- End Time: 2026-02-15T09:45:00Z
- Duration: 2700
- Input Files: 2 (1.8MB)
- Output Files: 2 (40KB)
- Errors Encountered: none
- Quality Self-Check: passed
<!-- TELEMETRY_END -->
```

## Non-Compliance

If an agent completes work without a journal entry, telemetry block, or checkpoint logging, the orchestrator MUST flag this as a quality failure and request the agent to retroactively document its work before proceeding.

## Remember

1. **If it's not written down, it didn't happen** — conversation context is ephemeral; files persist
2. **Auditability protects everyone** — the consultant, the client, and future engagements
3. **Conservative documentation > undocumented optimism** — when in doubt, write it down
4. **Future agents inherit this protocol** — no exceptions, no shortcuts
